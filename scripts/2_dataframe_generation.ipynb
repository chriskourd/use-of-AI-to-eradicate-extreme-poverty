{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from rasterio.features import geometry_window\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Filepaths ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'C:\\\\Users\\\\chris\\\\Desktop\\\\use-of-AI-to-eradicate-extreme-poverty'\n",
    "SETTLEMENT_DIRS = [\n",
    "    os.path.join(BASE_DIR, 'data/GlobalHumanSettlement/GHS_BUILT_S_E2020_GLOBE_R2023A_54009_100_V1_0_R11_C22.tif'),\n",
    "    os.path.join(BASE_DIR, 'data/GlobalHumanSettlement/GHS_BUILT_S_E2020_GLOBE_R2023A_54009_100_V1_0_R12_C22.tif')\n",
    "]\n",
    "NIGHTLIGHTS_DIR = os.path.join(BASE_DIR, 'data', 'nightlights', 'viirs_2020_00N060W.tif')\n",
    "ROADS_DIR = os.path.join(BASE_DIR, 'data', 'roads', 'GRIP4_density_total','grip4_total_dens_m_km2.asc')\n",
    "HEALTH_DIR = os.path.join(BASE_DIR, 'data', 'health_facilities', 'healthcare_2020.shp')\n",
    "LSMS_DIR = os.path.join(BASE_DIR, 'data', 'LSMS_2019')\n",
    "csv_file_path = os.path.join(LSMS_DIR, 'HouseholdGeovariables_csv', 'householdgeovariables_ihs5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processs LSMS data and incoorporate information for roads, buildup areas and nightlights ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in case_id: 0\n",
      "     cluster_lat  cluster_lon   gap_poor\n",
      "0     -17.093531    35.253139  16.549712\n",
      "1     -17.065680    35.166790  14.785578\n",
      "2     -17.028139    35.241661  12.760279\n",
      "3     -17.005220    35.082470  26.924220\n",
      "4     -16.964531    35.208618  16.837666\n",
      "..           ...          ...        ...\n",
      "704    -9.524120    33.278580   8.104608\n",
      "705    -9.514320    33.220600   3.447501\n",
      "706    -9.510990    33.137482  11.820492\n",
      "707    -9.398440    33.015339   8.899074\n",
      "708     0.000000     0.000000   6.327292\n",
      "\n",
      "[709 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def process_malawi():\n",
    "    # Define paths to data\n",
    "    lsms_dir = os.path.join(BASE_DIR, 'data', 'LSMS_2019')\n",
    "    consumption_file = os.path.join(lsms_dir, 'consumption_aggregate', 'ihs5_consumption_aggregate.csv')\n",
    "    geovariables_file = os.path.join(lsms_dir, 'HouseholdGeovariables_csv', 'householdgeovariables_ihs5.csv')\n",
    "    \n",
    "    # load consumption data\n",
    "    df = pd.read_csv(consumption_file)\n",
    "    df = df[['case_id', 'gap_poor']]  # Include only relevant columns\n",
    "\n",
    "    # load geovariables data\n",
    "    df_geo = pd.read_csv(geovariables_file)\n",
    "    df_geo = df_geo[['case_id', 'ea_lat_mod', 'ea_lon_mod']]\n",
    "    df_geo.rename(columns={'ea_lat_mod': 'cluster_lat', 'ea_lon_mod': 'cluster_lon'}, inplace=True)\n",
    "\n",
    "    # mwrge datasets on 'case_id'\n",
    "    df_combined = pd.merge(df, df_geo, on='case_id')\n",
    "\n",
    "    # check for duplicate case_ids before dropping it\n",
    "    duplicates = df_combined['case_id'].duplicated().sum()\n",
    "    print(f\"Number of duplicates in case_id: {duplicates}\")\n",
    "\n",
    "    # drop 'case_id' after checking for duplicates\n",
    "    df_combined.drop('case_id', axis=1, inplace=True)\n",
    "    df_combined.dropna(inplace=True)\n",
    "\n",
    "    # aggregate data by cluster\n",
    "    aggregation_functions = {\n",
    "        'gap_poor': 'mean'\n",
    "    }\n",
    "    df_clusters = df_combined.groupby(['cluster_lat', 'cluster_lon']).agg(aggregation_functions).reset_index()\n",
    "\n",
    "    return df_clusters[['cluster_lat', 'cluster_lon', 'gap_poor']]\n",
    "\n",
    "df_mw = process_malawi()\n",
    "print(df_mw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a buffer corcle around each point that corresponds to the aggregated questionnaire geolocations\n",
    "\n",
    "def circle_from_point(lat, lon, distance_km=5):\n",
    "    # calculate degrees from distance\n",
    "    earth_radius = 6371  # Radius of the Earth in kilometers\n",
    "    dLat = (distance_km / earth_radius) * (180 / math.pi)\n",
    "    dLon = dLat / math.cos(math.radians(lat))\n",
    "\n",
    "    # create a circle polygon for the given radius\n",
    "    return shapely.geometry.Point(lon, lat).buffer(dLat)  # Returns a circle around the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import geometry_window\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def circle_from_point(lat, lon, radius_km, target_crs='EPSG:4326', buffer_crs=None):\n",
    "    # Create a point GeoDataFrame\n",
    "    point = Point(lon, lat)\n",
    "    point_gdf = gpd.GeoDataFrame(index=[0], crs=target_crs, geometry=[point])\n",
    "    \n",
    "    # Determine an appropriate CRS for buffering if not provided\n",
    "    if not buffer_crs:\n",
    "        # Automatically determine UTM zone based on longitude\n",
    "        utm_zone = int(1 + (lon + 180.0) / 6.0)\n",
    "        hemi = 'N' if lat >= 0 else 'S'\n",
    "        buffer_crs = f'EPSG:326{utm_zone}' if hemi == 'N' else f'EPSG:327{utm_zone}'\n",
    "    \n",
    "    # Convert to a projected CRS to perform the buffering\n",
    "    point_gdf = point_gdf.to_crs(buffer_crs)\n",
    "    \n",
    "    # Perform the buffer in meters\n",
    "    buffer = point_gdf.buffer(radius_km * 1000)  # Buffer radius in meters\n",
    "    \n",
    "    # Convert the buffer back to the original CRS\n",
    "    buffer = buffer.to_crs(target_crs)\n",
    "    \n",
    "    return buffer.geometry[0]\n",
    "\n",
    "# Example usage within your main function:\n",
    "# Assuming you determine the radius and lat, lon as inputs somewhere in your code\n",
    "# circle = circle_from_point(lat, lon, 2.5)\n",
    "\n",
    "\n",
    "def calculate_average_value(subset, no_data_value):\n",
    "    subset = np.ma.masked_equal(subset, no_data_value)\n",
    "    if np.ma.is_masked(subset) and np.ma.count(subset) == 0:\n",
    "        return no_data_value\n",
    "    else:\n",
    "        return np.ma.mean(subset)\n",
    "\n",
    "def add_buildings_nightlights_roads_healthcare_values(df, buildings_tif_path, nightlights_tif_path, roads_tif_path, healthcare_tif_path, output_polygon_shapefile, output_point_shapefile):\n",
    "    with rasterio.open(buildings_tif_path) as buildings_raster, \\\n",
    "         rasterio.open(nightlights_tif_path) as nightlights_raster, \\\n",
    "         rasterio.open(roads_tif_path) as roads_raster, \\\n",
    "         rasterio.open(healthcare_tif_path) as healthcare_raster:\n",
    "\n",
    "        buildings_array = buildings_raster.read(1)\n",
    "        nightlights_array = nightlights_raster.read(1)\n",
    "        roads_array = roads_raster.read(1)\n",
    "        healthcare_array = healthcare_raster.read(1)\n",
    "\n",
    "        buildings_nodata = buildings_raster.nodata\n",
    "        nightlights_nodata = nightlights_raster.nodata\n",
    "        roads_nodata = roads_raster.nodata\n",
    "        healthcare_nodata = healthcare_raster.nodata\n",
    "\n",
    "        circles = []\n",
    "        points = []\n",
    "        for lat, lon in zip(df['cluster_lat'], df['cluster_lon']):\n",
    "            circle = circle_from_point(lat, lon, 2.5)  # 2.5 km radius circle\n",
    "            point = Point(lon, lat)\n",
    "            circles.append(circle)\n",
    "            points.append(point)\n",
    "\n",
    "        gdf_polygons = gpd.GeoDataFrame(df, geometry=circles, crs=\"EPSG:4326\")\n",
    "        gdf_points = gpd.GeoDataFrame(df, geometry=points, crs=\"EPSG:4326\")\n",
    "\n",
    "        builtup_area = []\n",
    "        nightlights_intensity = []\n",
    "        road_density = []\n",
    "        healthcare_access = []\n",
    "\n",
    "        for geometry in tqdm(gdf_polygons.geometry, desc=\"Processing circles\"):\n",
    "            for raster, array, results, no_data_value in [\n",
    "                (buildings_raster, buildings_array, builtup_area, buildings_nodata),\n",
    "                (nightlights_raster, nightlights_array, nightlights_intensity, nightlights_nodata),\n",
    "                (roads_raster, roads_array, road_density, roads_nodata),\n",
    "                (healthcare_raster, healthcare_array, healthcare_access, healthcare_nodata)]:\n",
    "\n",
    "                window = geometry_window(raster, [geometry], pad_x=0, pad_y=0, boundless=True)\n",
    "                if window.width > 0 and window.height > 0:\n",
    "                    subset = array[window.row_off:window.row_off + window.height, window.col_off:window.col_off + window.width]\n",
    "                    average_value = calculate_average_value(subset, no_data_value)\n",
    "                    results.append(average_value if average_value != no_data_value else 0)\n",
    "                else:\n",
    "                    results.append(0)\n",
    "\n",
    "        gdf_polygons['builtup_area'] = builtup_area\n",
    "        gdf_polygons['nightlights_intensity'] = nightlights_intensity\n",
    "        gdf_polygons['road_density'] = road_density\n",
    "        gdf_polygons['healthcare_access'] = healthcare_access\n",
    "\n",
    "        gdf_points['builtup_area'] = builtup_area\n",
    "        gdf_points['nightlights_intensity'] = nightlights_intensity\n",
    "        gdf_points['road_density'] = road_density\n",
    "        gdf_points['healthcare_access'] = healthcare_access\n",
    "\n",
    "        gdf_polygons.to_file(output_polygon_shapefile)\n",
    "        gdf_points.to_file(output_point_shapefile)\n",
    "\n",
    "    return gdf_polygons, gdf_points\n",
    "\n",
    "# Sample data paths\n",
    "BASE_DIR = r'C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty'\n",
    "buildings_tif_path = os.path.join(BASE_DIR, 'results', 'rasters', 'settlements_merged.tif')\n",
    "nightlights_tif_path = os.path.join(BASE_DIR, 'data', 'nightlights', 'viirs_2020_00N060W.tif')\n",
    "roads_tif_path = os.path.join(BASE_DIR, 'data', 'roads', 'GRIP4_density_total', 'grip4_total_dens_m_km2_4326.tif')\n",
    "healthcare_tif_path = os.path.join(BASE_DIR, 'results', 'rasters', 'healthcare_density.tif')\n",
    "output_point_shapefile = os.path.join(BASE_DIR, 'results', 'shapefiles', 'df_mw_points.shp')\n",
    "output_polygon_shapefile = os.path.join(BASE_DIR, 'results', 'shapefiles', 'df_mw_polygons.shp')\n",
    "\n",
    "# Assuming df_mw is already defined and contains necessary data\n",
    "gdf_circles, df_result = add_buildings_nightlights_roads_healthcare_values(df_mw, buildings_tif_path, nightlights_tif_path, roads_tif_path, healthcare_tif_path, output_polygon_shapefile, output_point_shapefile)\n",
    "\n",
    "# Print the result to verify\n",
    "print(df_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_lat  cluster_lon  builtup_area  nightlights_intensity  \\\n",
      "0     -17.093531    35.253139      3.753977               0.373688   \n",
      "1     -17.065680    35.166790     51.892308               0.411656   \n",
      "2     -17.028139    35.241661    147.284231               0.408638   \n",
      "3     -17.005220    35.082470     46.378846               0.586200   \n",
      "4     -16.964531    35.208618    255.686923               0.417670   \n",
      "..           ...          ...           ...                    ...   \n",
      "704    -9.524120    33.278580    199.118824               0.356244   \n",
      "705    -9.514320    33.220600    243.123922               0.366759   \n",
      "706    -9.510990    33.137482    154.129566               0.376157   \n",
      "707    -9.398440    33.015339    155.272203               0.372930   \n",
      "708     0.000000     0.000000           NaN                    NaN   \n",
      "\n",
      "     road_density   gap_poor  healthcare_access  \n",
      "0            83.5  16.549712           1.442405  \n",
      "1            83.5  14.785578           2.068308  \n",
      "2            61.0  12.760279           2.225611  \n",
      "3             0.0  26.924220           3.275340  \n",
      "4           131.0  16.837666           3.322957  \n",
      "..            ...        ...                ...  \n",
      "704           0.0   8.104608           4.507254  \n",
      "705          65.0   3.447501           3.986312  \n",
      "706          79.5  11.820492           3.301284  \n",
      "707          86.0   8.899074           2.134710  \n",
      "708           0.0   6.327292                NaN  \n",
      "\n",
      "[709 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_result[['cluster_lat', 'cluster_lon', 'builtup_area', 'nightlights_intensity', 'road_density', 'gap_poor', 'healthcare_access']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(os.path.join(BASE_DIR, 'results', 'dataframes', 'df_result.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                       gap_poor  builtup_area  nightlights_intensity  \\\n",
      "gap_poor               1.000000     -0.463781              -0.424101   \n",
      "builtup_area          -0.463781      1.000000               0.917905   \n",
      "nightlights_intensity -0.424101      0.917905               1.000000   \n",
      "road_density          -0.386729      0.773211               0.800203   \n",
      "healthcare_access     -0.140212      0.242120               0.307479   \n",
      "\n",
      "                       road_density  healthcare_access  \n",
      "gap_poor                  -0.386729          -0.140212  \n",
      "builtup_area               0.773211           0.242120  \n",
      "nightlights_intensity      0.800203           0.307479  \n",
      "road_density               1.000000           0.265555  \n",
      "healthcare_access          0.265555           1.000000  \n",
      "                       gap_poor  builtup_area  nightlights_intensity  \\\n",
      "gap_poor               1.000000     -0.463781              -0.424101   \n",
      "builtup_area          -0.463781      1.000000               0.917905   \n",
      "nightlights_intensity -0.424101      0.917905               1.000000   \n",
      "road_density          -0.386729      0.773211               0.800203   \n",
      "healthcare_access     -0.140212      0.242120               0.307479   \n",
      "\n",
      "                       road_density  healthcare_access  \n",
      "gap_poor                  -0.386729          -0.140212  \n",
      "builtup_area               0.773211           0.242120  \n",
      "nightlights_intensity      0.800203           0.307479  \n",
      "road_density               1.000000           0.265555  \n",
      "healthcare_access          0.265555           1.000000  \n"
     ]
    }
   ],
   "source": [
    "# function to calculate a correlation matrix\n",
    "\n",
    "def analyze_relationships(df):\n",
    "\n",
    "    features = ['gap_poor', 'builtup_area', 'nightlights_intensity', 'road_density', 'healthcare_access']\n",
    "    df_features = df[features]\n",
    "\n",
    "    # calculate the correlation matrix\n",
    "    correlation_matrix = df_features.corr()\n",
    "\n",
    "    print(\"Correlation Matrix:\")\n",
    "    print(correlation_matrix)\n",
    "\n",
    "    return correlation_matrix\n",
    "\n",
    "# call function\n",
    "correlation_matrix = analyze_relationships(df_result)\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python (poverty)",
   "language": "python",
   "name": "poverty"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
