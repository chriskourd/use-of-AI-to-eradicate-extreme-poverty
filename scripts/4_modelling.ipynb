{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from osgeo import gdal, osr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from rasterio.features import geometry_window, shapes, geometry_mask\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.enums import Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Filepaths ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'C:\\\\Users\\\\chris\\\\Desktop\\\\use-of-AI-to-eradicate-extreme-poverty'\n",
    "SETTLEMENT_DIRS = [\n",
    "    os.path.join(BASE_DIR, 'data/GlobalHumanSettlement/GHS_BUILT_S_E2020_GLOBE_R2023A_54009_100_V1_0_R11_C22.tif'),\n",
    "    os.path.join(BASE_DIR, 'data/GlobalHumanSettlement/GHS_BUILT_S_E2020_GLOBE_R2023A_54009_100_V1_0_R12_C22.tif')\n",
    "]\n",
    "NIGHTLIGHTS_DIR = os.path.join(BASE_DIR, 'data', 'nightlights', 'viirs_2020_00N060W.tif')\n",
    "ROADS_DIR = os.path.join(BASE_DIR, 'data', 'roads', 'GRIP4_density_total','grip4_total_dens_m_km2.asc')\n",
    "HEALTH_DIR = os.path.join(BASE_DIR, 'data', 'health_facilities', 'healthcare_2020.shp')\n",
    "LSMS_DIR = os.path.join(BASE_DIR, 'data', 'LSMS_2019')\n",
    "csv_file_path = os.path.join(LSMS_DIR, 'HouseholdGeovariables_csv', 'householdgeovariables_ihs5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitted model script ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|███████████████████████████████████████████████████████████| 3200/3200 [01:27<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Scaling features...\n",
      "Splitting dataset...\n",
      "Performing grid search...\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "Model saved to C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty\\results\\model\\best_model.joblib\n",
      "Best parameters found:  {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Predicting and evaluating...\n",
      "Evaluation Metrics:\n",
      "Mean Squared Error: 9.311295890005903\n",
      "Root Mean Squared Error: 3.0514416084870284\n",
      "R² Score: 0.8254775970704676\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "def load_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        nodata = src.nodata\n",
    "        return np.where(data == nodata, np.nan, data), src.profile\n",
    "\n",
    "def process_in_chunks(paths, chunk_size=10000):\n",
    "    data_list = []\n",
    "    labels_list = []\n",
    "    positions_list = []\n",
    "\n",
    "    with rasterio.open(paths[0]) as src:\n",
    "        height, width = src.shape\n",
    "        total_pixels = height * width\n",
    "        for i in tqdm(range(0, total_pixels, chunk_size), desc=\"Processing chunks\"):\n",
    "            row_start = i // width\n",
    "            col_start = i % width\n",
    "            row_end = row_start + (chunk_size // width)\n",
    "            col_end = col_start + chunk_size % width\n",
    "            \n",
    "            if col_end > width:\n",
    "                col_end = width\n",
    "\n",
    "            window = rasterio.windows.Window(col_start, row_start, col_end - col_start, row_end - row_start)\n",
    "\n",
    "            chunk_data = []\n",
    "            for path in paths:\n",
    "                with rasterio.open(path) as src:\n",
    "                    chunk = src.read(1, window=window)\n",
    "                    chunk_nodata = src.nodata\n",
    "                    chunk_data.append(np.where(chunk == chunk_nodata, np.nan, chunk).flatten())\n",
    "\n",
    "            valid_mask_chunk = ~np.isnan(chunk_data[0])\n",
    "            for data in chunk_data[1:]:\n",
    "                valid_mask_chunk &= ~np.isnan(data)\n",
    "\n",
    "            if np.any(valid_mask_chunk):\n",
    "                data_list.append(np.column_stack([data[valid_mask_chunk] for data in chunk_data[:-1]]))\n",
    "                labels_list.append(chunk_data[-1][valid_mask_chunk])\n",
    "                row_col_indices = np.column_stack(np.where(valid_mask_chunk.reshape(window.height, window.width)))\n",
    "                global_indices = row_col_indices + np.array([row_start, col_start])\n",
    "                positions_list.append(global_indices)\n",
    "\n",
    "    return np.vstack(data_list), np.concatenate(labels_list), np.vstack(positions_list), height, width\n",
    "\n",
    "BASE_DIR = r'C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty'\n",
    "model_results_dir = os.path.join(BASE_DIR, 'results', 'model')\n",
    "os.makedirs(model_results_dir, exist_ok=True)\n",
    "\n",
    "paths = [\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_nightlights.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_settlements.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_roads_density.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_healthcare.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'interpolation_gap_poor.tif')\n",
    "]\n",
    "\n",
    "print(\"Loading and processing data...\")\n",
    "features, labels, positions, height, width = process_in_chunks(paths)\n",
    "\n",
    "print(\"Handling missing values...\")\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "print(\"Scaling features...\")\n",
    "scaler = RobustScaler()\n",
    "features_scaled = scaler.fit_transform(features_imputed)\n",
    "\n",
    "print(\"Splitting dataset...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save the model\n",
    "model_save_path = os.path.join(model_results_dir, 'best_model.joblib')\n",
    "joblib.dump(best_model, model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Print best parameters and intermediate results\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "print(\"Predicting and evaluating...\")\n",
    "predictions = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|█████████████████████████████████████████████████████████████████| 99/99 [02:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features shape: (27482120, 4)\n",
      "Total positions shape: (27482120, 2)\n",
      "Raster dimensions: height=8871, width=3607\n",
      "Handling missing values...\n",
      "Missing values imputed.\n",
      "Scaling features...\n",
      "Features scaled.\n",
      "Loading the saved model...\n",
      "Predicting values...\n",
      "Non-resampled predictions raster saved at C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty\\results\\rasters\\predicted_gap_poor.tif\n",
      "Resampled rasters saved at C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty\\results\\rasters\\actual_gap_poor_8kmRes.tif and C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty\\results\\rasters\\predicted_gap_poor_8kmRes.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.warp import Resampling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        nodata = src.nodata\n",
    "        return np.where(data == nodata, np.nan, data), src.profile\n",
    "\n",
    "def process_in_overlapping_chunks(paths, height, width, chunk_size=100, overlap=10):\n",
    "    data_list = []\n",
    "    positions_list = []\n",
    "\n",
    "    step_size = chunk_size - overlap\n",
    "\n",
    "    for row in tqdm(range(0, height, step_size), desc=\"Processing rows\"):\n",
    "        for col in range(0, width, step_size):\n",
    "            row_end = min(row + chunk_size, height)\n",
    "            col_end = min(col + chunk_size, width)\n",
    "            \n",
    "            window = Window(col, row, col_end - col, row_end - row)\n",
    "\n",
    "            chunk_data = []\n",
    "            for path in paths:\n",
    "                with rasterio.open(path) as src:\n",
    "                    chunk = src.read(1, window=window)\n",
    "                    chunk_nodata = src.nodata\n",
    "                    chunk_data.append(np.where(chunk == chunk_nodata, np.nan, chunk).flatten())\n",
    "\n",
    "            valid_mask_chunk = ~np.isnan(chunk_data[0])\n",
    "            for data in chunk_data[1:]:\n",
    "                valid_mask_chunk &= ~np.isnan(data)\n",
    "\n",
    "            if np.any(valid_mask_chunk):\n",
    "                data_list.append(np.column_stack([data[valid_mask_chunk] for data in chunk_data]))\n",
    "                row_col_indices = np.column_stack(np.where(valid_mask_chunk.reshape(window.height, window.width)))\n",
    "                global_indices = row_col_indices + np.array([row, col])\n",
    "                positions_list.append(global_indices)\n",
    "\n",
    "    return np.vstack(data_list), np.vstack(positions_list), height, width\n",
    "\n",
    "def resample_raster(data, profile, new_resolution):\n",
    "    \"\"\"Resample raster data to a new resolution using the given scale factor.\"\"\"\n",
    "    scale_factor = new_resolution / profile['transform'][0]  # new_resolution / original pixel size in meters\n",
    "    new_height = int(data.shape[0] / scale_factor)\n",
    "    new_width = int(data.shape[1] / scale_factor)\n",
    "\n",
    "    new_data = np.empty((new_height, new_width), dtype=np.float32)\n",
    "    new_transform = profile['transform'] * profile['transform'].scale(scale_factor, scale_factor)\n",
    "\n",
    "    with rasterio.open(\n",
    "        '/vsimem/temp.tif', 'w',\n",
    "        driver='GTiff',\n",
    "        height=new_height,\n",
    "        width=new_width,\n",
    "        count=1,\n",
    "        dtype='float32',\n",
    "        crs=profile['crs'],\n",
    "        transform=new_transform,\n",
    "    ) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "    with rasterio.open('/vsimem/temp.tif') as src:\n",
    "        resampled_data = src.read(\n",
    "            1,\n",
    "            out_shape=(1, new_height, new_width),\n",
    "            resampling=Resampling.bilinear,\n",
    "        )\n",
    "        resampled_profile = src.profile\n",
    "\n",
    "    return resampled_data, resampled_profile\n",
    "\n",
    "BASE_DIR = r'C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty'\n",
    "model_results_dir = os.path.join(BASE_DIR, 'results', 'model')\n",
    "model_path = os.path.join(model_results_dir, 'best_model.joblib')\n",
    "\n",
    "paths = [\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_nightlights.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_settlements.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_roads_density.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_healthcare.tif')\n",
    "]\n",
    "\n",
    "print(\"Loading and processing data...\")\n",
    "with rasterio.open(paths[0]) as src:\n",
    "    height, width = src.shape\n",
    "\n",
    "features, positions, height, width = process_in_overlapping_chunks(paths, height, width)\n",
    "\n",
    "print(f\"Total features shape: {features.shape}\")\n",
    "print(f\"Total positions shape: {positions.shape}\")\n",
    "print(f\"Raster dimensions: height={height}, width={width}\")\n",
    "\n",
    "print(\"Handling missing values...\")\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "print(\"Missing values imputed.\")\n",
    "\n",
    "print(\"Scaling features...\")\n",
    "scaler = RobustScaler()\n",
    "features_scaled = scaler.fit_transform(features_imputed)\n",
    "print(\"Features scaled.\")\n",
    "\n",
    "print(\"Loading the saved model...\")\n",
    "best_model = joblib.load(model_path)\n",
    "\n",
    "# Prepare full predictions array\n",
    "full_predictions = np.full((height, width), np.nan)\n",
    "\n",
    "print(\"Predicting values...\")\n",
    "flat_predictions = best_model.predict(features_scaled)\n",
    "for (row, col), pred in zip(positions, flat_predictions):\n",
    "    full_predictions[row, col] = pred\n",
    "\n",
    "# Save the non-resampled predictions raster\n",
    "non_resampled_raster_path = os.path.join(BASE_DIR, 'results', 'rasters', 'predicted_gap_poor.tif')\n",
    "target_raster_path = os.path.join(BASE_DIR, 'results', 'rasters', 'interpolation_gap_poor.tif')\n",
    "with rasterio.open(target_raster_path) as src:\n",
    "    profile_target = src.profile\n",
    "\n",
    "profile_target['dtype'] = 'float32'\n",
    "profile_target['nodata'] = np.nan\n",
    "with rasterio.open(non_resampled_raster_path, 'w', **profile_target) as dst:\n",
    "    dst.write(full_predictions, 1)\n",
    "\n",
    "print(f\"Non-resampled predictions raster saved at {non_resampled_raster_path}\")\n",
    "\n",
    "# Load the actual raster\n",
    "actual_values, profile_actual = load_raster(target_raster_path)\n",
    "\n",
    "# Resample the actual and predicted rasters to 8km x 8km resolution\n",
    "new_resolution = 8000\n",
    "resampled_actual, profile_actual_resampled = resample_raster(actual_values, profile_target, new_resolution)\n",
    "resampled_predicted, profile_predicted_resampled = resample_raster(full_predictions, profile_target, new_resolution)\n",
    "\n",
    "# Save the resampled rasters\n",
    "resampled_actual_path = os.path.join(BASE_DIR, 'results', 'rasters', 'actual_gap_poor_8kmRes.tif')\n",
    "resampled_predicted_path = os.path.join(BASE_DIR, 'results', 'rasters', 'predicted_gap_poor_8kmRes.tif')\n",
    "with rasterio.open(resampled_actual_path, 'w', **profile_actual_resampled) as dst:\n",
    "    dst.write(resampled_actual, 1)\n",
    "\n",
    "with rasterio.open(resampled_predicted_path, 'w', **profile_predicted_resampled) as dst:\n",
    "    dst.write(resampled_predicted, 1)\n",
    "\n",
    "print(f\"Resampled rasters saved at {resampled_actual_path} and {resampled_predicted_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 3 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|███████████████████████████████████████████████████████████| 3200/3200 [01:13<00:00, 43.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Scaling features...\n",
      "Splitting dataset...\n",
      "Predicting and evaluating on train-test split...\n",
      "Evaluation Metrics on Train-Test Split:\n",
      "Mean Squared Error: 9.311295890005903\n",
      "Root Mean Squared Error: 3.0514416084870284\n",
      "R² Score: 0.8254775970704676\n",
      "Predicting on full raster...\n",
      "Full predictions raster saved at C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty\\results\\rasters\\predicted_gap_poor_full.tif\n",
      "Evaluation Metrics on Full Raster:\n",
      "Mean Squared Error: 8.883992\n",
      "Root Mean Squared Error: 2.9806027\n",
      "R² Score: 0.8337105884277722\n",
      "Train-Test Evaluation Metrics: MSE=9.311295890005903, RMSE=3.0514416084870284, R²=0.8254775970704676\n",
      "Full Raster Evaluation Metrics: MSE=8.883992195129395, RMSE=2.980602741241455, R²=0.8337105884277722\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# Define paths\n",
    "BASE_DIR = r'C:\\Users\\chris\\Desktop\\use-of-AI-to-eradicate-extreme-poverty'\n",
    "model_results_dir = os.path.join(BASE_DIR, 'results', 'model')\n",
    "predicted_raster_path = os.path.join(BASE_DIR, 'results', 'rasters', 'predicted_gap_poor.tif')\n",
    "actual_raster_path = os.path.join(BASE_DIR, 'results', 'rasters', 'interpolation_gap_poor.tif')\n",
    "\n",
    "# Load the actual and predicted rasters\n",
    "def load_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        nodata = src.nodata\n",
    "        return np.where(data == nodata, np.nan, data), src.profile\n",
    "\n",
    "def process_in_chunks(paths, chunk_size=10000):\n",
    "    data_list = []\n",
    "    labels_list = []\n",
    "    positions_list = []\n",
    "\n",
    "    with rasterio.open(paths[0]) as src:\n",
    "        height, width = src.shape\n",
    "        total_pixels = height * width\n",
    "        for i in tqdm(range(0, total_pixels, chunk_size), desc=\"Processing chunks\"):\n",
    "            row_start = i // width\n",
    "            col_start = i % width\n",
    "            row_end = row_start + (chunk_size // width)\n",
    "            col_end = col_start + chunk_size % width\n",
    "\n",
    "            if col_end > width:\n",
    "                col_end = width\n",
    "\n",
    "            window = rasterio.windows.Window(col_start, row_start, col_end - col_start, row_end - row_start)\n",
    "\n",
    "            chunk_data = []\n",
    "            for path in paths:\n",
    "                with rasterio.open(path) as src:\n",
    "                    chunk = src.read(1, window=window)\n",
    "                    chunk_nodata = src.nodata\n",
    "                    chunk_data.append(np.where(chunk == chunk_nodata, np.nan, chunk).flatten())\n",
    "\n",
    "            valid_mask_chunk = ~np.isnan(chunk_data[0])\n",
    "            for data in chunk_data[1:]:\n",
    "                valid_mask_chunk &= ~np.isnan(data)\n",
    "\n",
    "            if np.any(valid_mask_chunk):\n",
    "                data_list.append(np.column_stack([data[valid_mask_chunk] for data in chunk_data[:-1]]))\n",
    "                labels_list.append(chunk_data[-1][valid_mask_chunk])\n",
    "                row_col_indices = np.column_stack(np.where(valid_mask_chunk.reshape(window.height, window.width)))\n",
    "                global_indices = row_col_indices + np.array([row_start, col_start])\n",
    "                positions_list.append(global_indices)\n",
    "\n",
    "    return np.vstack(data_list), np.concatenate(labels_list), np.vstack(positions_list), height, width\n",
    "\n",
    "print(\"Loading and processing data...\")\n",
    "paths = [\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_nightlights.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_settlements.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_roads_density.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'aligned_healthcare.tif'),\n",
    "    os.path.join(BASE_DIR, 'results', 'rasters', 'interpolation_gap_poor.tif')\n",
    "]\n",
    "features, labels, positions, height, width = process_in_chunks(paths)\n",
    "\n",
    "print(\"Handling missing values...\")\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "print(\"Scaling features...\")\n",
    "scaler = RobustScaler()\n",
    "features_scaled = scaler.fit_transform(features_imputed)\n",
    "\n",
    "# Load the model\n",
    "model_path = os.path.join(model_results_dir, 'best_model.joblib')\n",
    "best_model = joblib.load(model_path)\n",
    "\n",
    "# Train-Test Evaluation\n",
    "print(\"Splitting dataset...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Predicting and evaluating on train-test split...\")\n",
    "predictions_test = best_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, predictions_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_test = r2_score(y_test, predictions_test)\n",
    "\n",
    "print(\"Evaluation Metrics on Train-Test Split:\")\n",
    "print(\"Mean Squared Error:\", mse_test)\n",
    "print(\"Root Mean Squared Error:\", rmse_test)\n",
    "print(\"R² Score:\", r2_test)\n",
    "\n",
    "# Plotting actual vs predicted for train-test split\n",
    "plt.scatter(y_test, predictions_test, alpha=0.3)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted (Train-Test Split)')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(model_results_dir, 'actual_vs_predicted_train_test.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plotting residuals for train-test split\n",
    "residuals_test = y_test - predictions_test\n",
    "plt.hist(residuals_test, bins=50, alpha=0.75)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals (Train-Test Split)')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(model_results_dir, 'residuals_histogram_train_test.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot distribution of actual vs predicted for train-test split\n",
    "plt.hist(y_test, bins=50, alpha=0.5, label='Actual Values', color='blue')\n",
    "plt.hist(predictions_test, bins=50, alpha=0.5, label='Predicted Values', color='orange')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Actual and Predicted Values (Train-Test Split)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(model_results_dir, 'value_distributions_train_test.png'))\n",
    "plt.close()\n",
    "\n",
    "# Full Raster Prediction\n",
    "print(\"Predicting on full raster...\")\n",
    "flat_predictions = best_model.predict(features_scaled)\n",
    "full_predictions = np.full((height, width), np.nan)\n",
    "for (row, col), pred in zip(positions, flat_predictions):\n",
    "    full_predictions[row, col] = pred\n",
    "\n",
    "# Save the full predictions raster\n",
    "profile_target = load_raster(actual_raster_path)[1]\n",
    "predicted_raster_path = os.path.join(BASE_DIR, 'results', 'rasters', 'predicted_gap_poor_full.tif')\n",
    "profile_target['dtype'] = 'float32'\n",
    "profile_target['nodata'] = np.nan\n",
    "with rasterio.open(predicted_raster_path, 'w', **profile_target) as dst:\n",
    "    dst.write(full_predictions, 1)\n",
    "\n",
    "print(f\"Full predictions raster saved at {predicted_raster_path}\")\n",
    "\n",
    "# Load the actual and full predicted rasters for evaluation\n",
    "actual_values, profile_actual = load_raster(actual_raster_path)\n",
    "predicted_values, profile_predicted = load_raster(predicted_raster_path)\n",
    "\n",
    "# Flatten the arrays and remove NaNs for comparison\n",
    "actual_flat = actual_values.flatten()\n",
    "predicted_flat = predicted_values.flatten()\n",
    "\n",
    "valid_mask = ~np.isnan(actual_flat) & ~np.isnan(predicted_flat)\n",
    "actual_flat = actual_flat[valid_mask]\n",
    "predicted_flat = predicted_flat[valid_mask]\n",
    "\n",
    "# Calculate evaluation metrics based on the full raster\n",
    "mse_full = mean_squared_error(actual_flat, predicted_flat)\n",
    "rmse_full = np.sqrt(mse_full)\n",
    "r2_full = r2_score(actual_flat, predicted_flat)\n",
    "\n",
    "print(\"Evaluation Metrics on Full Raster:\")\n",
    "print(\"Mean Squared Error:\", mse_full)\n",
    "print(\"Root Mean Squared Error:\", rmse_full)\n",
    "print(\"R² Score:\", r2_full)\n",
    "\n",
    "# Plotting actual vs predicted (full raster)\n",
    "plt.scatter(actual_flat, predicted_flat, alpha=0.3)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted (Full Raster)')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(model_results_dir, 'actual_vs_predicted_full.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plotting residuals (full raster)\n",
    "residuals_full = actual_flat - predicted_flat\n",
    "plt.hist(residuals_full, bins=50, alpha=0.75)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals (Full Raster)')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(model_results_dir, 'residuals_histogram_full.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot distribution of actual vs predicted (full raster)\n",
    "plt.hist(actual_flat, bins=50, alpha=0.5, label='Actual Values', color='blue')\n",
    "plt.hist(predicted_flat, bins=50, alpha=0.5, label='Predicted Values', color='orange')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Actual and Predicted Values (Full Raster)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(model_results_dir, 'value_distributions_full.png'))\n",
    "plt.close()\n",
    "\n",
    "# Display the original and predicted rasters for comparison (full raster)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "axs[0].imshow(actual_values, cmap='viridis', interpolation='nearest')\n",
    "axs[0].set_title('Actual Gap Poor Values (Full Raster)')\n",
    "axs[0].set_axis_off()\n",
    "axs[1].imshow(predicted_values, cmap='viridis', interpolation='nearest')\n",
    "axs[1].set_title('Predicted Gap Poor Values (Full Raster)')\n",
    "axs[1].set_axis_off()\n",
    "plt.savefig(os.path.join(model_results_dir, 'actual_predicted_comparison_full.png'))\n",
    "plt.close()\n",
    "\n",
    "# Print summary\n",
    "print(f\"Train-Test Evaluation Metrics: MSE={mse_test}, RMSE={rmse_test}, R²={r2_test}\")\n",
    "print(f\"Full Raster Evaluation Metrics: MSE={mse_full}, RMSE={rmse_full}, R²={r2_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python (poverty)",
   "language": "python",
   "name": "poverty"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
